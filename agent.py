from blip_utils import generate_caption, answer_question, check_image_text_match
from rag_utils import search_wikipedia, generate_response
import openai
import os
from dotenv import load_dotenv
load_dotenv()

# Load Groq API Key
openai.api_key = os.getenv("GROQ_API_KEY")
openai.api_base = "https://api.groq.com/openai/v1"  # ← CRITICAL for Groq to work

def decide_tool(user_message):
    prompt = f"""
You are an intelligent tool selector for a visual assistant. Your job is to decide which specialized function (tool) should be used to respond to the user's message, based on the content of their query and the image provided.

You must choose from the following tools:

- caption: Use this when the user wants a simple description or summary of what is visible in the image. Triggers include words like "describe", "what's in this image", or "what do you see".

- vqa: Use this when the user asks a direct question about something specific in the image — such as objects, colors, actions, or quantities. Triggers include "how many", "is there a", "what color", "who is", "where is", "do you see".

- get_info: Use this when the user asks for factual information about something seen in the image (like an object, place, or person) — especially if the assistant should look up external knowledge. Triggers include "tell me about", "what is", "give info on", "Wikipedia".

- compare_caption: Use this to compare the user given caption [this will be a caption for the image] with the one that will be generated by BLIP in our application. Triggers include description or caption of an image, or something like this in the user message "This image is about"  

- rag_answer: Use this when the user is asking a deeper or broader question that needs understanding the image **and** do not rely much on the external information, it is usually trash and unrelated. These are usually open-ended questions like "why is this important", "explain this scene", or "what's happening and why" or, Maybe some other questions that do not fall in the above mentioned category.

Rules:
- ALWAYS return exactly one tool name.
- Do NOT explain your reasoning.
- If the input is vague, default to 'caption'.

User message: \"{user_message.strip()}\"
Tool:
"""
    response = openai.ChatCompletion.create(
        model="llama3-8b-8192",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
        max_tokens=5
    )

    result = response["choices"][0]["message"]["content"].strip().lower()
    for tool in ["caption", "vqa", "compare_caption", "get_info", "rag_answer"]:
        if tool in result:
            return tool
    return "caption"

def process_user_message(image, message, user_caption=None):
    """
    Route the message to the appropriate tool and return results.
    user_caption is used only for 'compare_caption' task.
    """
    selected_tool = decide_tool(message)
    result = {"tool": selected_tool}

    if selected_tool == "caption":
        caption = generate_caption(image)
        result["caption"] = caption

    elif selected_tool == "vqa":
        answer = answer_question(image, message)
        result["answer"] = answer

    elif selected_tool == "compare_caption":
        if not user_caption:
            result["error"] = "User caption required for comparison."
        else:
            blip_caption = generate_caption(image)
            score = check_image_text_match(image, user_caption)
            result["blip_caption"] = blip_caption
            result["match_score"] = score

    elif selected_tool == "get_info":
        caption = generate_caption(image)
        wiki_text = search_wikipedia(caption)
        result["caption"] = caption
        result["wiki_info"] = wiki_text

    elif selected_tool == "rag_answer":
        caption = generate_caption(image)
        wiki_text = search_wikipedia(caption)
        llm_response = generate_response(caption, wiki_text, question=message)
        result["caption"] = caption
        result["wiki_info"] = wiki_text
        result["llm_response"] = llm_response

    else:
        result["error"] = "Unknown tool selected."

    return result
